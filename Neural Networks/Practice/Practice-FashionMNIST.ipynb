{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Session 5 Practice: Fashion MNIST with different Nets\n",
    "\n",
    "\n",
    "<img src=\"https://do3z7e6uuakno.cloudfront.net/uploads/event/logo/1112702/595053a7143adafce285b2e39ca04f1a.jpeg\" width=\"300\">\n",
    "\n",
    "\n",
    "### Example adapted by AI Saturdays Euskadi.\n",
    "\n",
    "The objective of this practice is to understand how Neural Networks are modelled with a given dataset.\n",
    "\n",
    "In particular, the dataset is the  __*Fashion MNIST*__, which was inspired by the famous [MNIST (created by Yann LeCun et al.)](http://yann.lecun.com/exdb/mnist/), but instead of classifying digits from 0 to 9, you'll classify __clothes__.\n",
    "\n",
    "For this, the dataset contains the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| :-: | :- |\n",
    "| 0 | T-shirt / Top |\n",
    "| 1 | Trousers |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- You'll be using Python 3.\n",
    "- You'll use Python's libraries: Pandas, Numpy, Keras.\n",
    "\n",
    "**Completing the exercise, you´ll learn to:**\n",
    "- Better use and understand Python NoteBooks.\n",
    "- Be able to use python functions and additional libraries.\n",
    "- Correctly apply the NN algorithm.\n",
    "- Improve the predictions using Hyperparameter Tunning\n",
    "- Compare with other NN Architectures, adjusting parameters.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be working withh Keras, we need to install all libraries related to Keras. We recommend to install Tensorflow directly. It is the package containing the library Keras, and it's developed by Google. [Tensorflow documentation](https://www.tensorflow.org/learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One - liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the dataset.\n",
    "\n",
    "This dataset is integrated within Keras. In particular within ```tensorflow.keras.datasets.fashion_mnist```. Hence we'll directly use the method ```load_data()``` to fetch the Train and Test sets.\n",
    "\n",
    "Before processing the dataset, take a look at the following [link](https://knowyourdata-tfds.withgoogle.com/#dataset=fashion_mnist&tab=STATS&select=kyd%2Ffashion_mnist%2Flabel&expanded_groups=cloud_vision,fashion_mnist)  to better understand the dataset. Play around with it to see train / test distribution, and other interesting insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the proportion of Train / Test?__\n",
    "- *Your answer*\n",
    "\n",
    "__How many pictures have faces?__\n",
    "- *Your answer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-liner.\n",
    "(x_train, y_train), (x_test, y_test) = \"Your code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "print(x_train[0][9]) # We´ll leave this here for you..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make the dataset 1-dimensional.\n",
    "\n",
    "Same as in the original MNIST, we have files containing pictures. These are matrixes of 28x28 pixels. \n",
    "\n",
    "We are going to be applying different models, but the first one is the 1-layer Perceptron. For this model we need to have the data in Long format, in a vector-like format.\n",
    "\n",
    "We need to modify the training and test data, to later get the into categorical variables.\n",
    "\n",
    "__Tips: ```reshape()``` and ```to_categorical()```.__\n",
    "\n",
    "Before reshaping, keep in mind the color in each pixel is expressed in a scale 0 to 256... (divide by the maximum, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four lines of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the sizes of the target variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into detail about the activation functions, we leave this \"Golden Rule\" for you to write down:\n",
    "\n",
    "1. Use ReLU ('relu') cuando puedas, para las neuronas de cada capa oculta.\n",
    "2. Use Softmax ('softmax') when you want to make a classification and your output has more than two categories.\n",
    "3. Use Sigmoid ('sigmoid') when your output has two categories.\n",
    "As you'll see next, models are formed of the following sections:\n",
    "\n",
    "* ```Sequential()```: Tells Keras that you''ll add a sequence of layers.\n",
    "* ```add()```: Adds the layer with the details you need. In the first layer that you define you need to specify the input's shape (```input_dim```). It's not necessary in the following.\n",
    "* ```compile()```: This defines how the Net is going to be trained (Loss Function, Optimizer and metric to optimize towards.\n",
    "\n",
    "Having stated this, let's create the first model based on the Perceptron to solve the Classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will __train__ the model. As you can see, we need to specify the number of *epochs*, which are the complete iterations over the dataset, as well as the train and validation split. For the split, a 0.1 indicates a 10% Validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained the model, let's __evaluate__ the model's accuracy over the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model 1__: We've achieved an accuracy close to  __84%__... ¡Let's see how we can improve this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model 2: Perceptron with more neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do as for Model 1, though this time with 50 Neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model 2__: We have now achieved an accuracy of  __87%__, it has clearly increased! Let's see if we can imporve it more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model 3: Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll add a __new layer to the Perceptron__. \n",
    "\n",
    "Ideally, we will obtain a better output (the deeper the net, it's supposed to generalise better and it is better adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model 3__: We have got an accuracy of approximately __88%__... Has it improved? Yes, though not much.\n",
    "\n",
    "What about trying with a __diffferent architecture__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model 4: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into detail - this is the scope of another of our courses ;) - a  __Convolutional Neural Network (CNN)__ allows for better image recognition than the Perceptron, due to the mathematical operations that drive it internally.\n",
    "\n",
    "Therefore, we will make an example of how are they typically used. Notice there are mre imports now:\n",
    "\n",
    "* ```Conv2D```: Allows 2-dimensional convolution operations.\n",
    "* ```MaxPooling2D```: Allows 2-dimensional pooling operations.\n",
    "* ```Flatten```: Makes it easy to get the data into Long format (flattening the data).\n",
    "\n",
    "They are usually used in a sequential way, mainly because of how the Convolution works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# Train / Test Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "### CNN layers\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Represent the Model's architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(model4, show_shapes=True, show_layer_names=True) #https://graphviz.gitlab.io/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡WOW! It performs better than the previous architectures...with an accuracy of almost __90%__.\n",
    "\n",
    "Although somewhat expected, it has been seen that __CNNs__ are good for processing images due to the Convolution operation.\n",
    "\n",
    "However, it is not part of the Machine Learning curriculum to cover how wonderful these are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
