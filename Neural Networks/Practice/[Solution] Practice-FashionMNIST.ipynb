{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Session 5 Practice: Fashion MNIST with different Nets <font color=\"red\"> SOLUTION </font>**\n",
    "\n",
    "\n",
    "<img src=\"https://do3z7e6uuakno.cloudfront.net/uploads/event/logo/1112702/595053a7143adafce285b2e39ca04f1a.jpeg\" width=\"300\">\n",
    "\n",
    "\n",
    "### Example adapted by AI Saturdays Euskadi.\n",
    "\n",
    "The objective of this practice is to understand how Neural Networks are modelled with a given dataset.\n",
    "\n",
    "In particular, the dataset is the  __*Fashion MNIST*__, which was inspired by the famous [MNIST (created by Yann LeCun et al.)](http://yann.lecun.com/exdb/mnist/), but instead of classifying digits from 0 to 9, you'll classify __clothes__.\n",
    "\n",
    "For this, the dataset contains the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| :-: | :- |\n",
    "| 0 | T-shirt / Top |\n",
    "| 1 | Trousers |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- You'll be using Python 3.\n",
    "- You'll use Python's libraries: Pandas, Numpy, Keras.\n",
    "\n",
    "**Completing the exercise, youÂ´ll learn to:**\n",
    "- Better use and understand Python NoteBooks.\n",
    "- Be able to use python functions and additional libraries.\n",
    "- Correctly apply the NN algorithm.\n",
    "- Improve the predictions using Hyperparameter Tunning\n",
    "- Compare with other NN Architectures, adjusting parameters.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be working withh Keras, we need to install all libraries related to Keras. We recommend to install Tensorflow directly. It is the package containing the library Keras, and it's developed by Google. [Tensorflow documentation](https://www.tensorflow.org/learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dksomir\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (50.3.1.post20201107)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.15.8)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Installing collected packages: libclang, tensorflow-io-gcs-filesystem, keras, tensorboard, tf-estimator-nightly, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "Successfully installed keras-2.8.0 libclang-13.0.0 tensorboard-2.8.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the dataset.\n",
    "\n",
    "This dataset is integrated within Keras. In particular within ```tensorflow.keras.datasets.fashion_mnist```. Hence we'll directly use the method ```load_data()``` to fetch the Train and Test sets.\n",
    "\n",
    "Before processing the dataset, take a look at the following [link](https://knowyourdata-tfds.withgoogle.com/#dataset=fashion_mnist&tab=STATS&select=kyd%2Ffashion_mnist%2Flabel&expanded_groups=cloud_vision,fashion_mnist)  to better understand the dataset. Play around with it to see train / test distribution, and other interesting insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the proportion of Train / Test?__\n",
    "- *Your answer*\n",
    "\n",
    "__How many pictures have faces?__\n",
    "- *Your answer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-liner.\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      " 235 227 224 222 224 221 223 245 173   0]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the dataset\n",
    "print(x_train[0][9]) # WeÂ´ll leave this here for you..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make the dataset 1-dimensional.\n",
    "\n",
    "Same as in the original MNIST, we have files containing pictures. These are matrixes of 28x28 pixels. \n",
    "\n",
    "We are going to be applying different models, but the first one is the 1-layer Perceptron. For this model we need to have the data in Long format, in a vector-like format.\n",
    "\n",
    "We need to modify the training and test data, to later get the into categorical variables.\n",
    "\n",
    "__Tips: ```reshape()``` and ```to_categorical()```.__\n",
    "\n",
    "Before reshaping, keep in mind the color in each pixel is expressed in a scale 0 to 256..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four lines of code\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Print out the sizes of the target variables\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into detail about the activation functions, we leave this \"Golden Rule\" for you to write down:\n",
    "\n",
    "1. Use ReLU ('relu') cuando puedas, para las neuronas de cada capa oculta.\n",
    "2. Use Softmax ('softmax') when you want to make a classification and your output has more than two categories.\n",
    "3. Use Sigmoid ('sigmoid') when your output has two categories.\n",
    "As you'll see next, models are formed of the following sections:\n",
    "\n",
    "* ```Sequential()```: Tells Keras that you''ll add a sequence of layers.\n",
    "* ```add()```: Adds the layer with the details you need. In the first layer that you define you need to specify the input's shape (```input_dim```). It's not necessary in the following.\n",
    "* ```compile()```: This defines how the Net is going to be trained (Loss Function, Optimizer and metric to optimize towards.\n",
    "\n",
    "Having stated this, let's create the first model based on the Perceptron to solve the Classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will __train__ the model. As you can see, we need to specify the number of *epochs*, which are the complete iterations over the dataset, as well as the train and validation split. For the split, a 0.1 indicates a 10% Validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.7369 - accuracy: 0.7356 - val_loss: 0.4979 - val_accuracy: 0.8300\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.4597 - accuracy: 0.8411 - val_loss: 0.4452 - val_accuracy: 0.8435\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 928us/step - loss: 0.4288 - accuracy: 0.8512 - val_loss: 0.4392 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 946us/step - loss: 0.4077 - accuracy: 0.8589 - val_loss: 0.4228 - val_accuracy: 0.8483\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 966us/step - loss: 0.3976 - accuracy: 0.8619 - val_loss: 0.4090 - val_accuracy: 0.8552\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 953us/step - loss: 0.3881 - accuracy: 0.8647 - val_loss: 0.3976 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 935us/step - loss: 0.3817 - accuracy: 0.8667 - val_loss: 0.3986 - val_accuracy: 0.8620\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 972us/step - loss: 0.3771 - accuracy: 0.8675 - val_loss: 0.4309 - val_accuracy: 0.8463\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 937us/step - loss: 0.3707 - accuracy: 0.8704 - val_loss: 0.3941 - val_accuracy: 0.8617\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 2s 951us/step - loss: 0.3666 - accuracy: 0.8719 - val_loss: 0.4063 - val_accuracy: 0.8578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c18dec2e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained the model, let's __evaluate__ the model's accuracy over the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 733us/step - loss: 0.4412 - accuracy: 0.8483\n",
      "0.8482999801635742\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model 1__: We've achieved an accuracy close to  __84%__... Â¡Let's see how we can improve this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model 2: Perceptron with more neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do as for Model 1, though this time with 50 Neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=784, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.5459 - accuracy: 0.8105 - val_loss: 0.4409 - val_accuracy: 0.8443\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.4124 - accuracy: 0.8531 - val_loss: 0.3956 - val_accuracy: 0.8625\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3718 - accuracy: 0.8676 - val_loss: 0.3714 - val_accuracy: 0.8688\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3476 - accuracy: 0.8747 - val_loss: 0.3506 - val_accuracy: 0.8728\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3298 - accuracy: 0.8808 - val_loss: 0.3477 - val_accuracy: 0.8757\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3157 - accuracy: 0.8849 - val_loss: 0.3708 - val_accuracy: 0.8702\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3046 - accuracy: 0.8890 - val_loss: 0.3804 - val_accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2931 - accuracy: 0.8910 - val_loss: 0.3785 - val_accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2823 - accuracy: 0.8959 - val_loss: 0.3874 - val_accuracy: 0.8657\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2781 - accuracy: 0.8970 - val_loss: 0.3607 - val_accuracy: 0.8752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c18f5d1f70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 910us/step - loss: 0.3723 - accuracy: 0.8711\n",
      "0.8711000084877014\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "_, test_acc = model2.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model 2__: We have now achieved an accuracy of  __87%__, it has clearly increased! Let's see if we can imporve it more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model 3: Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll add a __new layer to the Perceptron__. \n",
    "\n",
    "Ideally, we will obtain a better output (the deeper the net, it's supposed to generalise better and it is better adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(50, input_dim=784, activation='relu'))\n",
    "model3.add(Dense(50, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.8782 - val_loss: 0.3446 - val_accuracy: 0.8723\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3154 - accuracy: 0.8844 - val_loss: 0.3360 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3039 - accuracy: 0.8889 - val_loss: 0.3743 - val_accuracy: 0.8687\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2929 - accuracy: 0.8912 - val_loss: 0.3448 - val_accuracy: 0.8783\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2806 - accuracy: 0.8956 - val_loss: 0.3549 - val_accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2714 - accuracy: 0.8971 - val_loss: 0.3306 - val_accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2630 - accuracy: 0.9015 - val_loss: 0.3303 - val_accuracy: 0.8840\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2559 - accuracy: 0.9056 - val_loss: 0.3378 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2481 - accuracy: 0.9071 - val_loss: 0.3452 - val_accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.2423 - accuracy: 0.9088 - val_loss: 0.3441 - val_accuracy: 0.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1b687d4f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 990us/step - loss: 0.3516 - accuracy: 0.8788\n",
      "0.8787999749183655\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "_, test_acc = model3.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modelo 3__: We have got an accuracy of approximately __88%__... Has it improved? Yes, though not much.\n",
    "\n",
    "What about trying with a __diffferent architecture__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model 4: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into detail - this is the scope of another of our courses ;) - a  __Convolutional Neural Network (CNN)__ allows for better image recognition than the Perceptron, due to the mathematical operations that drive it internally.\n",
    "\n",
    "Therefore, we leave an example of how are they typically used. Notice ther eare mre imports now:\n",
    "\n",
    "* ```Conv2D```: Allows 2-dimensional convolution operations.\n",
    "* ```MaxPooling2D```: Allows 2-dimensional pooling operations.\n",
    "* ```Flatten```: Makes it easy to get the data into Long format (flattening the data).\n",
    "\n",
    "They are usually used in a sequential way, mainly because of how the Convolution works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "import numpy as np\n",
    "\n",
    "# Train / Test Split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train[:,:,:,np.newaxis] / 255.0\n",
    "x_test = x_test[:,:,:,np.newaxis] / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) \n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                125450    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,770\n",
      "Trainable params: 125,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Represent the Model's architecture\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model_to_dot(model4, show_shapes=True, show_layer_names=True) #https://graphviz.gitlab.io/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 25s 15ms/step - loss: 0.4369 - accuracy: 0.8475 - val_loss: 0.3459 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 27s 16ms/step - loss: 0.3148 - accuracy: 0.8893 - val_loss: 0.2983 - val_accuracy: 0.8940\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 27s 16ms/step - loss: 0.2819 - accuracy: 0.9011 - val_loss: 0.2968 - val_accuracy: 0.8940\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 27s 16ms/step - loss: 0.2604 - accuracy: 0.9070 - val_loss: 0.2815 - val_accuracy: 0.8953\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 68s 40ms/step - loss: 0.2432 - accuracy: 0.9139 - val_loss: 0.2798 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 113s 67ms/step - loss: 0.2290 - accuracy: 0.9184 - val_loss: 0.2897 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.2182 - accuracy: 0.9213 - val_loss: 0.2788 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 59s 35ms/step - loss: 0.2078 - accuracy: 0.9254 - val_loss: 0.2795 - val_accuracy: 0.9023\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 59s 35ms/step - loss: 0.1976 - accuracy: 0.9289 - val_loss: 0.2800 - val_accuracy: 0.9042\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 65s 39ms/step - loss: 0.1898 - accuracy: 0.9316 - val_loss: 0.2871 - val_accuracy: 0.9023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1786b8100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model4.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2951 - accuracy: 0.8988\n",
      "0.8988000154495239\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "_, test_acc = model4.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¡WOW! It performs better than the previous architectures...with an accuracy of almost __90%__.\n",
    "\n",
    "Although somewhat expected, it has been seen that __CNNs__ are good for processing images due to the Convolution operation.\n",
    "\n",
    "However, it is not part of the Machine Learning curriculum to cover how wonderful these are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
